{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\AppData\\Roaming\\Python\\Python39\\site-packages\\ale_py\\roms\\__init__.py:89: DeprecationWarning: Automatic importing of atari-py roms won't be supported in future releases of ale-py. Please migrate over to using `ale-import-roms` OR an ALE-supported ROM package. To make this warning disappear you can run `ale-import-roms --import-from-pkg atari_py.atari_roms`.For more information see: https://github.com/mgbellemare/Arcade-Learning-Environment#rom-management\n",
      "  ROMS = resolve_roms()\n"
     ]
    }
   ],
   "source": [
    "from lib import wrappers\n",
    "from lib import dqn_model\n",
    "import time\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_ENV_NAME = \"BreakoutNoFrameskip-v4\"\n",
    "MEAN_REWARD_BOUND = 19.5\n",
    "EPSILON_DECAY_LAST_FRAME = 10**5\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_FINAL = 0.02\n",
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 32\n",
    "REPLAY_SIZE = 10000\n",
    "LEARNING_RATE = 1e-4\n",
    "SYNC_TARGET_FRAMES = 1000\n",
    "REPLAY_START_SIZE = 10000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experienced Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experience = collections.namedtuple('Experience', field_names=['state', 'action', 'reward', 'done', 'new_state'])\n",
    "\n",
    "class ExperienceBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = collections.deque(maxlen=capacity)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def append(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        indices = np.random.choice(len(self.buffer), batch_size, replace=False)\n",
    "        states, actions, rewards, dones, next_states = zip(*[self.buffer[idx] for idx in indices])\n",
    "        return np.array(states), np.array(actions), np.array(rewards, dtype=np.float32), \\\n",
    "               np.array(dones, dtype=np.uint8), np.array(next_states)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, env, exp_buffer):\n",
    "        self.env = env\n",
    "        self.exp_buffer = exp_buffer\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self):\n",
    "        self.state = env.reset()\n",
    "        self.total_reward = 0.0\n",
    "\n",
    "    def play_step(self, net, epsilon=0.0, device=\"cpu\"):\n",
    "        done_reward = None\n",
    "\n",
    "        if np.random.random() < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            state_a = np.array([self.state], copy=False)\n",
    "            state_v = torch.tensor(state_a).to(device)\n",
    "            q_vals_v = net(state_v)\n",
    "            _, act_v = torch.max(q_vals_v, dim=1)\n",
    "            action = int(act_v.item())\n",
    "\n",
    "        # do step in the environment\n",
    "        new_state, reward, is_done, _ = self.env.step(action)\n",
    "        self.total_reward += reward\n",
    "\n",
    "        exp = Experience(self.state, action, reward, is_done, new_state)\n",
    "        self.exp_buffer.append(exp)\n",
    "        self.state = new_state\n",
    "        if is_done:\n",
    "            done_reward = self.total_reward\n",
    "            self._reset()\n",
    "        return done_reward"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(batch, net, tgt_net, device=\"cpu\"):\n",
    "    states, actions, rewards, dones, next_states = batch\n",
    "\n",
    "    states_v = torch.tensor(states).to(device)\n",
    "    next_states_v = torch.tensor(next_states).to(device)\n",
    "    actions_v = torch.tensor(actions).to(device)\n",
    "    rewards_v = torch.tensor(rewards).to(device)\n",
    "    done_mask = torch.ByteTensor(dones).to(device)\n",
    "\n",
    "    actions_v2 = actions_v.unsqueeze(-1).long()\n",
    "\n",
    "    state_action_values = net(states_v).gather(1, actions_v2).squeeze(-1)\n",
    "    \n",
    "    next_state_values = tgt_net(next_states_v).max(1)[0]\n",
    "    next_state_values[done_mask] = 0.0\n",
    "    next_state_values = next_state_values.detach()\n",
    "\n",
    "    expected_state_action_values = next_state_values * GAMMA + rewards_v\n",
    "    return nn.MSELoss()(state_action_values, expected_state_action_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=3136, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=4, bias=True)\n",
      "  )\n",
      ")\n",
      "198 frames over 1 games, mean reward 2.000, eps 1.00, speed 1069.33 f/s\n",
      "355 frames over 2 games, mean reward 1.500, eps 1.00, speed 1058.78 f/s\n",
      "529 frames over 3 games, mean reward 1.333, eps 0.99, speed 996.34 f/s\n",
      "969 frames over 4 games, mean reward 1.250, eps 0.99, speed 870.41 f/s\n",
      "1318 frames over 5 games, mean reward 1.200, eps 0.99, speed 872.36 f/s\n",
      "1570 frames over 6 games, mean reward 1.500, eps 0.98, speed 878.58 f/s\n",
      "2062 frames over 7 games, mean reward 1.714, eps 0.98, speed 900.55 f/s\n",
      "2506 frames over 8 games, mean reward 1.625, eps 0.97, speed 882.79 f/s\n",
      "2715 frames over 9 games, mean reward 1.667, eps 0.97, speed 874.08 f/s\n",
      "3028 frames over 10 games, mean reward 1.600, eps 0.97, speed 827.72 f/s\n",
      "3188 frames over 11 games, mean reward 1.545, eps 0.97, speed 871.66 f/s\n",
      "3363 frames over 12 games, mean reward 1.500, eps 0.97, speed 836.92 f/s\n",
      "3629 frames over 13 games, mean reward 1.615, eps 0.96, speed 859.61 f/s\n",
      "3806 frames over 14 games, mean reward 1.571, eps 0.96, speed 915.96 f/s\n",
      "4185 frames over 15 games, mean reward 1.667, eps 0.96, speed 912.31 f/s\n",
      "4385 frames over 16 games, mean reward 1.688, eps 0.96, speed 862.94 f/s\n",
      "4561 frames over 17 games, mean reward 1.647, eps 0.95, speed 890.51 f/s\n",
      "5010 frames over 18 games, mean reward 1.611, eps 0.95, speed 806.35 f/s\n",
      "5281 frames over 19 games, mean reward 1.684, eps 0.95, speed 829.94 f/s\n",
      "5454 frames over 20 games, mean reward 1.650, eps 0.95, speed 875.43 f/s\n",
      "5646 frames over 21 games, mean reward 1.667, eps 0.94, speed 826.52 f/s\n",
      "5954 frames over 22 games, mean reward 1.682, eps 0.94, speed 822.45 f/s\n",
      "6269 frames over 23 games, mean reward 1.652, eps 0.94, speed 850.10 f/s\n",
      "6435 frames over 24 games, mean reward 1.625, eps 0.94, speed 797.73 f/s\n",
      "6783 frames over 25 games, mean reward 1.640, eps 0.93, speed 846.87 f/s\n",
      "6993 frames over 26 games, mean reward 1.654, eps 0.93, speed 853.05 f/s\n",
      "7228 frames over 27 games, mean reward 1.704, eps 0.93, speed 821.63 f/s\n",
      "7385 frames over 28 games, mean reward 1.679, eps 0.93, speed 829.23 f/s\n",
      "7701 frames over 29 games, mean reward 1.655, eps 0.92, speed 809.85 f/s\n",
      "8294 frames over 30 games, mean reward 1.667, eps 0.92, speed 787.76 f/s\n",
      "8519 frames over 31 games, mean reward 1.677, eps 0.91, speed 782.10 f/s\n",
      "8747 frames over 32 games, mean reward 1.719, eps 0.91, speed 811.03 f/s\n",
      "8910 frames over 33 games, mean reward 1.697, eps 0.91, speed 862.49 f/s\n",
      "9066 frames over 34 games, mean reward 1.676, eps 0.91, speed 788.31 f/s\n",
      "9806 frames over 35 games, mean reward 1.686, eps 0.90, speed 792.64 f/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\AppData\\Local\\Temp\\ipykernel_13536\\98137925.py:15: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorAdvancedIndexing.cpp:1773.)\n",
      "  next_state_values[done_mask] = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10089 frames over 36 games, mean reward 1.667, eps 0.90, speed 102.23 f/s\n",
      "10286 frames over 37 games, mean reward 1.676, eps 0.90, speed 35.16 f/s\n",
      "10726 frames over 38 games, mean reward 1.658, eps 0.89, speed 34.77 f/s\n",
      "11285 frames over 39 games, mean reward 1.641, eps 0.89, speed 32.72 f/s\n",
      "11484 frames over 40 games, mean reward 1.650, eps 0.89, speed 31.90 f/s\n",
      "11648 frames over 41 games, mean reward 1.634, eps 0.88, speed 32.51 f/s\n",
      "11821 frames over 42 games, mean reward 1.619, eps 0.88, speed 32.48 f/s\n",
      "12425 frames over 43 games, mean reward 1.628, eps 0.88, speed 33.21 f/s\n",
      "12658 frames over 44 games, mean reward 1.659, eps 0.87, speed 32.69 f/s\n",
      "12923 frames over 45 games, mean reward 1.711, eps 0.87, speed 32.46 f/s\n",
      "13122 frames over 46 games, mean reward 1.717, eps 0.87, speed 32.43 f/s\n",
      "13325 frames over 47 games, mean reward 1.723, eps 0.87, speed 32.22 f/s\n",
      "13507 frames over 48 games, mean reward 1.729, eps 0.86, speed 31.85 f/s\n",
      "13728 frames over 49 games, mean reward 1.735, eps 0.86, speed 32.00 f/s\n",
      "13898 frames over 50 games, mean reward 1.720, eps 0.86, speed 31.63 f/s\n",
      "14197 frames over 51 games, mean reward 1.706, eps 0.86, speed 31.26 f/s\n",
      "14415 frames over 52 games, mean reward 1.712, eps 0.86, speed 31.99 f/s\n",
      "14597 frames over 53 games, mean reward 1.698, eps 0.85, speed 30.26 f/s\n",
      "14782 frames over 54 games, mean reward 1.704, eps 0.85, speed 30.59 f/s\n",
      "14994 frames over 55 games, mean reward 1.709, eps 0.85, speed 30.21 f/s\n",
      "15210 frames over 56 games, mean reward 1.732, eps 0.85, speed 28.43 f/s\n",
      "15408 frames over 57 games, mean reward 1.737, eps 0.85, speed 27.84 f/s\n",
      "15597 frames over 58 games, mean reward 1.724, eps 0.84, speed 29.15 f/s\n",
      "15789 frames over 59 games, mean reward 1.712, eps 0.84, speed 30.49 f/s\n",
      "15999 frames over 60 games, mean reward 1.717, eps 0.84, speed 30.27 f/s\n",
      "16351 frames over 61 games, mean reward 1.721, eps 0.84, speed 30.52 f/s\n",
      "16521 frames over 62 games, mean reward 1.710, eps 0.83, speed 30.85 f/s\n",
      "16683 frames over 63 games, mean reward 1.698, eps 0.83, speed 30.19 f/s\n",
      "16883 frames over 64 games, mean reward 1.703, eps 0.83, speed 30.59 f/s\n",
      "17067 frames over 65 games, mean reward 1.708, eps 0.83, speed 30.69 f/s\n",
      "17219 frames over 66 games, mean reward 1.697, eps 0.83, speed 30.68 f/s\n",
      "17383 frames over 67 games, mean reward 1.687, eps 0.83, speed 30.95 f/s\n",
      "17610 frames over 68 games, mean reward 1.691, eps 0.82, speed 30.94 f/s\n",
      "17885 frames over 69 games, mean reward 1.710, eps 0.82, speed 30.68 f/s\n",
      "18051 frames over 70 games, mean reward 1.700, eps 0.82, speed 30.30 f/s\n",
      "18254 frames over 71 games, mean reward 1.704, eps 0.82, speed 30.57 f/s\n",
      "18701 frames over 72 games, mean reward 1.750, eps 0.81, speed 30.87 f/s\n",
      "19173 frames over 73 games, mean reward 1.740, eps 0.81, speed 30.44 f/s\n",
      "19344 frames over 74 games, mean reward 1.730, eps 0.81, speed 30.70 f/s\n",
      "19960 frames over 75 games, mean reward 1.733, eps 0.80, speed 30.33 f/s\n",
      "20396 frames over 76 games, mean reward 1.724, eps 0.80, speed 30.40 f/s\n",
      "20974 frames over 77 games, mean reward 1.714, eps 0.79, speed 30.49 f/s\n",
      "21213 frames over 78 games, mean reward 1.718, eps 0.79, speed 30.60 f/s\n",
      "21722 frames over 79 games, mean reward 1.734, eps 0.78, speed 30.44 f/s\n",
      "21995 frames over 80 games, mean reward 1.750, eps 0.78, speed 28.69 f/s\n",
      "22175 frames over 81 games, mean reward 1.753, eps 0.78, speed 28.45 f/s\n",
      "22517 frames over 82 games, mean reward 1.756, eps 0.77, speed 28.93 f/s\n",
      "22720 frames over 83 games, mean reward 1.759, eps 0.77, speed 28.98 f/s\n",
      "22891 frames over 84 games, mean reward 1.750, eps 0.77, speed 29.18 f/s\n",
      "23233 frames over 85 games, mean reward 1.753, eps 0.77, speed 28.99 f/s\n",
      "23429 frames over 86 games, mean reward 1.756, eps 0.77, speed 29.42 f/s\n",
      "23690 frames over 87 games, mean reward 1.770, eps 0.76, speed 29.23 f/s\n",
      "23868 frames over 88 games, mean reward 1.761, eps 0.76, speed 27.13 f/s\n",
      "24054 frames over 89 games, mean reward 1.753, eps 0.76, speed 28.33 f/s\n",
      "24410 frames over 90 games, mean reward 1.756, eps 0.76, speed 28.50 f/s\n",
      "24569 frames over 91 games, mean reward 1.747, eps 0.75, speed 30.28 f/s\n",
      "24813 frames over 92 games, mean reward 1.761, eps 0.75, speed 28.18 f/s\n",
      "24968 frames over 93 games, mean reward 1.753, eps 0.75, speed 30.12 f/s\n",
      "25163 frames over 94 games, mean reward 1.745, eps 0.75, speed 30.08 f/s\n",
      "25354 frames over 95 games, mean reward 1.737, eps 0.75, speed 29.40 f/s\n",
      "25648 frames over 96 games, mean reward 1.729, eps 0.74, speed 29.87 f/s\n",
      "26065 frames over 97 games, mean reward 1.722, eps 0.74, speed 29.84 f/s\n",
      "26620 frames over 98 games, mean reward 1.714, eps 0.73, speed 29.87 f/s\n",
      "26870 frames over 99 games, mean reward 1.727, eps 0.73, speed 29.74 f/s\n",
      "27152 frames over 100 games, mean reward 1.750, eps 0.73, speed 29.88 f/s\n",
      "27375 frames over 101 games, mean reward 1.760, eps 0.73, speed 29.99 f/s\n",
      "27588 frames over 102 games, mean reward 1.770, eps 0.72, speed 28.15 f/s\n",
      "27960 frames over 103 games, mean reward 1.790, eps 0.72, speed 28.75 f/s\n",
      "28187 frames over 104 games, mean reward 1.810, eps 0.72, speed 29.43 f/s\n",
      "28445 frames over 105 games, mean reward 1.830, eps 0.72, speed 29.58 f/s\n",
      "28908 frames over 106 games, mean reward 1.880, eps 0.71, speed 29.49 f/s\n",
      "29136 frames over 107 games, mean reward 1.880, eps 0.71, speed 29.19 f/s\n",
      "29365 frames over 108 games, mean reward 1.890, eps 0.71, speed 29.34 f/s\n",
      "29738 frames over 109 games, mean reward 1.900, eps 0.70, speed 29.10 f/s\n",
      "30016 frames over 110 games, mean reward 1.930, eps 0.70, speed 29.14 f/s\n",
      "30221 frames over 111 games, mean reward 1.940, eps 0.70, speed 29.18 f/s\n",
      "30500 frames over 112 games, mean reward 1.970, eps 0.70, speed 29.46 f/s\n",
      "30863 frames over 113 games, mean reward 2.000, eps 0.69, speed 29.28 f/s\n",
      "31025 frames over 114 games, mean reward 2.000, eps 0.69, speed 29.18 f/s\n",
      "31228 frames over 115 games, mean reward 1.990, eps 0.69, speed 29.35 f/s\n",
      "31428 frames over 116 games, mean reward 1.990, eps 0.69, speed 29.29 f/s\n",
      "31616 frames over 117 games, mean reward 1.990, eps 0.68, speed 29.20 f/s\n",
      "31886 frames over 118 games, mean reward 2.020, eps 0.68, speed 29.57 f/s\n",
      "Best mean reward updated 2.000 -> 2.020, model saved\n",
      "32073 frames over 119 games, mean reward 2.010, eps 0.68, speed 29.31 f/s\n",
      "32492 frames over 120 games, mean reward 2.090, eps 0.68, speed 29.45 f/s\n",
      "Best mean reward updated 2.020 -> 2.090, model saved\n",
      "32788 frames over 121 games, mean reward 2.110, eps 0.67, speed 29.57 f/s\n",
      "Best mean reward updated 2.090 -> 2.110, model saved\n",
      "33044 frames over 122 games, mean reward 2.130, eps 0.67, speed 29.22 f/s\n",
      "Best mean reward updated 2.110 -> 2.130, model saved\n",
      "33262 frames over 123 games, mean reward 2.150, eps 0.67, speed 29.25 f/s\n",
      "Best mean reward updated 2.130 -> 2.150, model saved\n",
      "33678 frames over 124 games, mean reward 2.240, eps 0.66, speed 29.51 f/s\n",
      "Best mean reward updated 2.150 -> 2.240, model saved\n",
      "34044 frames over 125 games, mean reward 2.280, eps 0.66, speed 29.23 f/s\n",
      "Best mean reward updated 2.240 -> 2.280, model saved\n",
      "34275 frames over 126 games, mean reward 2.290, eps 0.66, speed 29.18 f/s\n",
      "Best mean reward updated 2.280 -> 2.290, model saved\n",
      "34510 frames over 127 games, mean reward 2.290, eps 0.65, speed 29.00 f/s\n",
      "34779 frames over 128 games, mean reward 2.320, eps 0.65, speed 29.05 f/s\n",
      "Best mean reward updated 2.290 -> 2.320, model saved\n",
      "35105 frames over 129 games, mean reward 2.360, eps 0.65, speed 28.99 f/s\n",
      "Best mean reward updated 2.320 -> 2.360, model saved\n",
      "35290 frames over 130 games, mean reward 2.360, eps 0.65, speed 28.86 f/s\n",
      "35572 frames over 131 games, mean reward 2.380, eps 0.64, speed 29.28 f/s\n",
      "Best mean reward updated 2.360 -> 2.380, model saved\n",
      "35794 frames over 132 games, mean reward 2.380, eps 0.64, speed 29.23 f/s\n",
      "36002 frames over 133 games, mean reward 2.380, eps 0.64, speed 29.14 f/s\n",
      "36333 frames over 134 games, mean reward 2.420, eps 0.64, speed 29.27 f/s\n",
      "Best mean reward updated 2.380 -> 2.420, model saved\n",
      "36629 frames over 135 games, mean reward 2.440, eps 0.63, speed 29.19 f/s\n",
      "Best mean reward updated 2.420 -> 2.440, model saved\n",
      "37025 frames over 136 games, mean reward 2.530, eps 0.63, speed 29.20 f/s\n",
      "Best mean reward updated 2.440 -> 2.530, model saved\n",
      "37248 frames over 137 games, mean reward 2.540, eps 0.63, speed 28.99 f/s\n",
      "Best mean reward updated 2.530 -> 2.540, model saved\n",
      "37543 frames over 138 games, mean reward 2.580, eps 0.62, speed 29.04 f/s\n",
      "Best mean reward updated 2.540 -> 2.580, model saved\n",
      "37783 frames over 139 games, mean reward 2.600, eps 0.62, speed 28.82 f/s\n",
      "Best mean reward updated 2.580 -> 2.600, model saved\n",
      "38156 frames over 140 games, mean reward 2.650, eps 0.62, speed 28.89 f/s\n",
      "Best mean reward updated 2.600 -> 2.650, model saved\n",
      "38385 frames over 141 games, mean reward 2.670, eps 0.62, speed 28.87 f/s\n",
      "Best mean reward updated 2.650 -> 2.670, model saved\n",
      "38614 frames over 142 games, mean reward 2.690, eps 0.61, speed 29.08 f/s\n",
      "Best mean reward updated 2.670 -> 2.690, model saved\n",
      "38840 frames over 143 games, mean reward 2.700, eps 0.61, speed 28.79 f/s\n",
      "Best mean reward updated 2.690 -> 2.700, model saved\n",
      "39103 frames over 144 games, mean reward 2.710, eps 0.61, speed 28.87 f/s\n",
      "Best mean reward updated 2.700 -> 2.710, model saved\n",
      "39402 frames over 145 games, mean reward 2.750, eps 0.61, speed 28.85 f/s\n",
      "Best mean reward updated 2.710 -> 2.750, model saved\n",
      "39801 frames over 146 games, mean reward 2.800, eps 0.60, speed 28.85 f/s\n",
      "Best mean reward updated 2.750 -> 2.800, model saved\n",
      "40115 frames over 147 games, mean reward 2.830, eps 0.60, speed 28.74 f/s\n",
      "Best mean reward updated 2.800 -> 2.830, model saved\n",
      "40436 frames over 148 games, mean reward 2.860, eps 0.60, speed 28.79 f/s\n",
      "Best mean reward updated 2.830 -> 2.860, model saved\n",
      "40641 frames over 149 games, mean reward 2.860, eps 0.59, speed 28.56 f/s\n",
      "40954 frames over 150 games, mean reward 2.900, eps 0.59, speed 28.38 f/s\n",
      "Best mean reward updated 2.860 -> 2.900, model saved\n",
      "41220 frames over 151 games, mean reward 2.930, eps 0.59, speed 26.93 f/s\n",
      "Best mean reward updated 2.900 -> 2.930, model saved\n",
      "41433 frames over 152 games, mean reward 2.940, eps 0.59, speed 24.72 f/s\n",
      "Best mean reward updated 2.930 -> 2.940, model saved\n",
      "41630 frames over 153 games, mean reward 2.950, eps 0.58, speed 23.99 f/s\n",
      "Best mean reward updated 2.940 -> 2.950, model saved\n",
      "41894 frames over 154 games, mean reward 2.960, eps 0.58, speed 27.98 f/s\n",
      "Best mean reward updated 2.950 -> 2.960, model saved\n",
      "42108 frames over 155 games, mean reward 2.960, eps 0.58, speed 28.30 f/s\n",
      "42390 frames over 156 games, mean reward 2.970, eps 0.58, speed 25.74 f/s\n",
      "Best mean reward updated 2.960 -> 2.970, model saved\n",
      "42855 frames over 157 games, mean reward 3.030, eps 0.57, speed 24.19 f/s\n",
      "Best mean reward updated 2.970 -> 3.030, model saved\n",
      "43133 frames over 158 games, mean reward 3.060, eps 0.57, speed 26.30 f/s\n",
      "Best mean reward updated 3.030 -> 3.060, model saved\n",
      "43359 frames over 159 games, mean reward 3.080, eps 0.57, speed 24.25 f/s\n",
      "Best mean reward updated 3.060 -> 3.080, model saved\n",
      "43812 frames over 160 games, mean reward 3.140, eps 0.56, speed 27.22 f/s\n",
      "Best mean reward updated 3.080 -> 3.140, model saved\n",
      "44094 frames over 161 games, mean reward 3.160, eps 0.56, speed 26.86 f/s\n",
      "Best mean reward updated 3.140 -> 3.160, model saved\n",
      "44302 frames over 162 games, mean reward 3.180, eps 0.56, speed 26.76 f/s\n",
      "Best mean reward updated 3.160 -> 3.180, model saved\n",
      "44646 frames over 163 games, mean reward 3.230, eps 0.55, speed 28.84 f/s\n",
      "Best mean reward updated 3.180 -> 3.230, model saved\n",
      "45154 frames over 164 games, mean reward 3.300, eps 0.55, speed 29.74 f/s\n",
      "Best mean reward updated 3.230 -> 3.300, model saved\n",
      "45382 frames over 165 games, mean reward 3.310, eps 0.55, speed 29.53 f/s\n",
      "Best mean reward updated 3.300 -> 3.310, model saved\n",
      "45551 frames over 166 games, mean reward 3.310, eps 0.54, speed 29.42 f/s\n",
      "45798 frames over 167 games, mean reward 3.330, eps 0.54, speed 29.89 f/s\n",
      "Best mean reward updated 3.310 -> 3.330, model saved\n",
      "46085 frames over 168 games, mean reward 3.360, eps 0.54, speed 29.64 f/s\n",
      "Best mean reward updated 3.330 -> 3.360, model saved\n",
      "46380 frames over 169 games, mean reward 3.380, eps 0.54, speed 29.55 f/s\n",
      "Best mean reward updated 3.360 -> 3.380, model saved\n",
      "46742 frames over 170 games, mean reward 3.430, eps 0.53, speed 29.32 f/s\n",
      "Best mean reward updated 3.380 -> 3.430, model saved\n",
      "47020 frames over 171 games, mean reward 3.450, eps 0.53, speed 29.41 f/s\n",
      "Best mean reward updated 3.430 -> 3.450, model saved\n",
      "47275 frames over 172 games, mean reward 3.440, eps 0.53, speed 29.21 f/s\n",
      "47552 frames over 173 games, mean reward 3.470, eps 0.52, speed 29.20 f/s\n",
      "Best mean reward updated 3.450 -> 3.470, model saved\n",
      "47882 frames over 174 games, mean reward 3.490, eps 0.52, speed 29.37 f/s\n",
      "Best mean reward updated 3.470 -> 3.490, model saved\n",
      "48083 frames over 175 games, mean reward 3.490, eps 0.52, speed 29.36 f/s\n",
      "48572 frames over 176 games, mean reward 3.580, eps 0.51, speed 29.31 f/s\n",
      "Best mean reward updated 3.490 -> 3.580, model saved\n",
      "49027 frames over 177 games, mean reward 3.670, eps 0.51, speed 29.36 f/s\n",
      "Best mean reward updated 3.580 -> 3.670, model saved\n",
      "49619 frames over 178 games, mean reward 3.780, eps 0.50, speed 29.33 f/s\n",
      "Best mean reward updated 3.670 -> 3.780, model saved\n",
      "49904 frames over 179 games, mean reward 3.800, eps 0.50, speed 29.31 f/s\n",
      "Best mean reward updated 3.780 -> 3.800, model saved\n",
      "50270 frames over 180 games, mean reward 3.830, eps 0.50, speed 29.37 f/s\n",
      "Best mean reward updated 3.800 -> 3.830, model saved\n",
      "50548 frames over 181 games, mean reward 3.860, eps 0.49, speed 29.41 f/s\n",
      "Best mean reward updated 3.830 -> 3.860, model saved\n",
      "50889 frames over 182 games, mean reward 3.900, eps 0.49, speed 29.33 f/s\n",
      "Best mean reward updated 3.860 -> 3.900, model saved\n",
      "51311 frames over 183 games, mean reward 3.950, eps 0.49, speed 29.16 f/s\n",
      "Best mean reward updated 3.900 -> 3.950, model saved\n",
      "51659 frames over 184 games, mean reward 4.010, eps 0.48, speed 29.20 f/s\n",
      "Best mean reward updated 3.950 -> 4.010, model saved\n",
      "51858 frames over 185 games, mean reward 4.010, eps 0.48, speed 29.20 f/s\n",
      "52238 frames over 186 games, mean reward 4.060, eps 0.48, speed 29.18 f/s\n",
      "Best mean reward updated 4.010 -> 4.060, model saved\n",
      "52510 frames over 187 games, mean reward 4.070, eps 0.47, speed 29.09 f/s\n",
      "Best mean reward updated 4.060 -> 4.070, model saved\n",
      "52930 frames over 188 games, mean reward 4.140, eps 0.47, speed 29.30 f/s\n",
      "Best mean reward updated 4.070 -> 4.140, model saved\n",
      "53299 frames over 189 games, mean reward 4.190, eps 0.47, speed 28.96 f/s\n",
      "Best mean reward updated 4.140 -> 4.190, model saved\n",
      "53746 frames over 190 games, mean reward 4.250, eps 0.46, speed 29.33 f/s\n",
      "Best mean reward updated 4.190 -> 4.250, model saved\n",
      "54083 frames over 191 games, mean reward 4.300, eps 0.46, speed 29.29 f/s\n",
      "Best mean reward updated 4.250 -> 4.300, model saved\n",
      "54465 frames over 192 games, mean reward 4.330, eps 0.46, speed 29.12 f/s\n",
      "Best mean reward updated 4.300 -> 4.330, model saved\n",
      "54649 frames over 193 games, mean reward 4.340, eps 0.45, speed 28.98 f/s\n",
      "Best mean reward updated 4.330 -> 4.340, model saved\n",
      "54920 frames over 194 games, mean reward 4.370, eps 0.45, speed 29.20 f/s\n",
      "Best mean reward updated 4.340 -> 4.370, model saved\n",
      "55449 frames over 195 games, mean reward 4.440, eps 0.45, speed 29.39 f/s\n",
      "Best mean reward updated 4.370 -> 4.440, model saved\n",
      "55780 frames over 196 games, mean reward 4.470, eps 0.44, speed 29.43 f/s\n",
      "Best mean reward updated 4.440 -> 4.470, model saved\n",
      "56211 frames over 197 games, mean reward 4.550, eps 0.44, speed 29.47 f/s\n",
      "Best mean reward updated 4.470 -> 4.550, model saved\n",
      "56632 frames over 198 games, mean reward 4.620, eps 0.43, speed 29.37 f/s\n",
      "Best mean reward updated 4.550 -> 4.620, model saved\n",
      "56956 frames over 199 games, mean reward 4.650, eps 0.43, speed 29.31 f/s\n",
      "Best mean reward updated 4.620 -> 4.650, model saved\n",
      "57203 frames over 200 games, mean reward 4.640, eps 0.43, speed 29.15 f/s\n",
      "57365 frames over 201 games, mean reward 4.620, eps 0.43, speed 29.58 f/s\n",
      "58015 frames over 202 games, mean reward 4.770, eps 0.42, speed 29.40 f/s\n",
      "Best mean reward updated 4.650 -> 4.770, model saved\n",
      "58239 frames over 203 games, mean reward 4.760, eps 0.42, speed 29.29 f/s\n",
      "58562 frames over 204 games, mean reward 4.780, eps 0.41, speed 29.46 f/s\n",
      "Best mean reward updated 4.770 -> 4.780, model saved\n",
      "58857 frames over 205 games, mean reward 4.790, eps 0.41, speed 29.13 f/s\n",
      "Best mean reward updated 4.780 -> 4.790, model saved\n",
      "59171 frames over 206 games, mean reward 4.760, eps 0.41, speed 29.38 f/s\n",
      "59667 frames over 207 games, mean reward 4.820, eps 0.40, speed 29.65 f/s\n",
      "Best mean reward updated 4.790 -> 4.820, model saved\n",
      "60191 frames over 208 games, mean reward 4.900, eps 0.40, speed 28.99 f/s\n",
      "Best mean reward updated 4.820 -> 4.900, model saved\n",
      "60633 frames over 209 games, mean reward 4.960, eps 0.39, speed 25.75 f/s\n",
      "Best mean reward updated 4.900 -> 4.960, model saved\n",
      "61040 frames over 210 games, mean reward 5.000, eps 0.39, speed 26.23 f/s\n",
      "Best mean reward updated 4.960 -> 5.000, model saved\n",
      "61494 frames over 211 games, mean reward 5.060, eps 0.39, speed 27.05 f/s\n",
      "Best mean reward updated 5.000 -> 5.060, model saved\n",
      "61919 frames over 212 games, mean reward 5.090, eps 0.38, speed 28.39 f/s\n",
      "Best mean reward updated 5.060 -> 5.090, model saved\n",
      "62294 frames over 213 games, mean reward 5.100, eps 0.38, speed 29.68 f/s\n",
      "Best mean reward updated 5.090 -> 5.100, model saved\n",
      "62569 frames over 214 games, mean reward 5.130, eps 0.37, speed 29.46 f/s\n",
      "Best mean reward updated 5.100 -> 5.130, model saved\n",
      "62813 frames over 215 games, mean reward 5.140, eps 0.37, speed 28.81 f/s\n",
      "Best mean reward updated 5.130 -> 5.140, model saved\n",
      "62976 frames over 216 games, mean reward 5.130, eps 0.37, speed 28.71 f/s\n",
      "63520 frames over 217 games, mean reward 5.320, eps 0.36, speed 29.14 f/s\n",
      "Best mean reward updated 5.140 -> 5.320, model saved\n",
      "63978 frames over 218 games, mean reward 5.360, eps 0.36, speed 29.03 f/s\n",
      "Best mean reward updated 5.320 -> 5.360, model saved\n",
      "64310 frames over 219 games, mean reward 5.400, eps 0.36, speed 29.08 f/s\n",
      "Best mean reward updated 5.360 -> 5.400, model saved\n",
      "64744 frames over 220 games, mean reward 5.390, eps 0.35, speed 28.93 f/s\n",
      "65084 frames over 221 games, mean reward 5.410, eps 0.35, speed 29.16 f/s\n",
      "Best mean reward updated 5.400 -> 5.410, model saved\n",
      "65481 frames over 222 games, mean reward 5.450, eps 0.35, speed 28.90 f/s\n",
      "Best mean reward updated 5.410 -> 5.450, model saved\n",
      "65770 frames over 223 games, mean reward 5.470, eps 0.34, speed 28.54 f/s\n",
      "Best mean reward updated 5.450 -> 5.470, model saved\n",
      "66032 frames over 224 games, mean reward 5.410, eps 0.34, speed 28.72 f/s\n",
      "66292 frames over 225 games, mean reward 5.390, eps 0.34, speed 28.84 f/s\n",
      "66727 frames over 226 games, mean reward 5.440, eps 0.33, speed 28.71 f/s\n",
      "67016 frames over 227 games, mean reward 5.460, eps 0.33, speed 28.94 f/s\n",
      "67413 frames over 228 games, mean reward 5.490, eps 0.33, speed 28.78 f/s\n",
      "Best mean reward updated 5.470 -> 5.490, model saved\n",
      "67749 frames over 229 games, mean reward 5.500, eps 0.32, speed 28.77 f/s\n",
      "Best mean reward updated 5.490 -> 5.500, model saved\n",
      "68328 frames over 230 games, mean reward 5.590, eps 0.32, speed 28.87 f/s\n",
      "Best mean reward updated 5.500 -> 5.590, model saved\n",
      "68620 frames over 231 games, mean reward 5.600, eps 0.31, speed 28.80 f/s\n",
      "Best mean reward updated 5.590 -> 5.600, model saved\n",
      "68941 frames over 232 games, mean reward 5.690, eps 0.31, speed 28.81 f/s\n",
      "Best mean reward updated 5.600 -> 5.690, model saved\n",
      "69542 frames over 233 games, mean reward 5.850, eps 0.30, speed 28.91 f/s\n",
      "Best mean reward updated 5.690 -> 5.850, model saved\n",
      "69848 frames over 234 games, mean reward 5.840, eps 0.30, speed 28.66 f/s\n",
      "70305 frames over 235 games, mean reward 5.890, eps 0.30, speed 28.87 f/s\n",
      "Best mean reward updated 5.850 -> 5.890, model saved\n",
      "70818 frames over 236 games, mean reward 5.890, eps 0.29, speed 28.94 f/s\n",
      "71203 frames over 237 games, mean reward 5.930, eps 0.29, speed 28.89 f/s\n",
      "Best mean reward updated 5.890 -> 5.930, model saved\n",
      "71656 frames over 238 games, mean reward 5.960, eps 0.28, speed 28.86 f/s\n",
      "Best mean reward updated 5.930 -> 5.960, model saved\n",
      "72103 frames over 239 games, mean reward 6.050, eps 0.28, speed 29.10 f/s\n",
      "Best mean reward updated 5.960 -> 6.050, model saved\n",
      "72556 frames over 240 games, mean reward 6.060, eps 0.27, speed 29.04 f/s\n",
      "Best mean reward updated 6.050 -> 6.060, model saved\n",
      "73098 frames over 241 games, mean reward 6.140, eps 0.27, speed 29.09 f/s\n",
      "Best mean reward updated 6.060 -> 6.140, model saved\n",
      "73474 frames over 242 games, mean reward 6.180, eps 0.27, speed 29.26 f/s\n",
      "Best mean reward updated 6.140 -> 6.180, model saved\n",
      "74171 frames over 243 games, mean reward 6.270, eps 0.26, speed 29.30 f/s\n",
      "Best mean reward updated 6.180 -> 6.270, model saved\n",
      "74683 frames over 244 games, mean reward 6.330, eps 0.25, speed 29.03 f/s\n",
      "Best mean reward updated 6.270 -> 6.330, model saved\n",
      "75085 frames over 245 games, mean reward 6.320, eps 0.25, speed 29.27 f/s\n",
      "75661 frames over 246 games, mean reward 6.400, eps 0.24, speed 29.33 f/s\n",
      "Best mean reward updated 6.330 -> 6.400, model saved\n",
      "76097 frames over 247 games, mean reward 6.420, eps 0.24, speed 29.37 f/s\n",
      "Best mean reward updated 6.400 -> 6.420, model saved\n",
      "76413 frames over 248 games, mean reward 6.430, eps 0.24, speed 29.43 f/s\n",
      "Best mean reward updated 6.420 -> 6.430, model saved\n",
      "76894 frames over 249 games, mean reward 6.520, eps 0.23, speed 29.48 f/s\n",
      "Best mean reward updated 6.430 -> 6.520, model saved\n",
      "77378 frames over 250 games, mean reward 6.600, eps 0.23, speed 29.48 f/s\n",
      "Best mean reward updated 6.520 -> 6.600, model saved\n",
      "77785 frames over 251 games, mean reward 6.670, eps 0.22, speed 29.46 f/s\n",
      "Best mean reward updated 6.600 -> 6.670, model saved\n",
      "78314 frames over 252 games, mean reward 6.790, eps 0.22, speed 29.49 f/s\n",
      "Best mean reward updated 6.670 -> 6.790, model saved\n",
      "78806 frames over 253 games, mean reward 6.890, eps 0.21, speed 29.19 f/s\n",
      "Best mean reward updated 6.790 -> 6.890, model saved\n",
      "79168 frames over 254 games, mean reward 6.940, eps 0.21, speed 29.44 f/s\n",
      "Best mean reward updated 6.890 -> 6.940, model saved\n",
      "79561 frames over 255 games, mean reward 6.980, eps 0.20, speed 29.56 f/s\n",
      "Best mean reward updated 6.940 -> 6.980, model saved\n",
      "80011 frames over 256 games, mean reward 7.030, eps 0.20, speed 29.54 f/s\n",
      "Best mean reward updated 6.980 -> 7.030, model saved\n",
      "80550 frames over 257 games, mean reward 7.050, eps 0.19, speed 29.45 f/s\n",
      "Best mean reward updated 7.030 -> 7.050, model saved\n",
      "80918 frames over 258 games, mean reward 7.080, eps 0.19, speed 29.56 f/s\n",
      "Best mean reward updated 7.050 -> 7.080, model saved\n",
      "81257 frames over 259 games, mean reward 7.120, eps 0.19, speed 29.24 f/s\n",
      "Best mean reward updated 7.080 -> 7.120, model saved\n",
      "81604 frames over 260 games, mean reward 7.110, eps 0.18, speed 29.49 f/s\n",
      "82020 frames over 261 games, mean reward 7.140, eps 0.18, speed 29.43 f/s\n",
      "Best mean reward updated 7.120 -> 7.140, model saved\n",
      "82508 frames over 262 games, mean reward 7.230, eps 0.17, speed 29.63 f/s\n",
      "Best mean reward updated 7.140 -> 7.230, model saved\n",
      "83012 frames over 263 games, mean reward 7.280, eps 0.17, speed 29.40 f/s\n",
      "Best mean reward updated 7.230 -> 7.280, model saved\n",
      "83579 frames over 264 games, mean reward 7.320, eps 0.16, speed 29.36 f/s\n",
      "Best mean reward updated 7.280 -> 7.320, model saved\n",
      "83869 frames over 265 games, mean reward 7.340, eps 0.16, speed 29.68 f/s\n",
      "Best mean reward updated 7.320 -> 7.340, model saved\n",
      "84447 frames over 266 games, mean reward 7.520, eps 0.16, speed 29.60 f/s\n",
      "Best mean reward updated 7.340 -> 7.520, model saved\n",
      "84960 frames over 267 games, mean reward 7.600, eps 0.15, speed 29.64 f/s\n",
      "Best mean reward updated 7.520 -> 7.600, model saved\n",
      "85285 frames over 268 games, mean reward 7.640, eps 0.15, speed 29.60 f/s\n",
      "Best mean reward updated 7.600 -> 7.640, model saved\n",
      "85779 frames over 269 games, mean reward 7.680, eps 0.14, speed 29.23 f/s\n",
      "Best mean reward updated 7.640 -> 7.680, model saved\n",
      "86424 frames over 270 games, mean reward 7.780, eps 0.14, speed 28.57 f/s\n",
      "Best mean reward updated 7.680 -> 7.780, model saved\n",
      "86874 frames over 271 games, mean reward 7.830, eps 0.13, speed 26.36 f/s\n",
      "Best mean reward updated 7.780 -> 7.830, model saved\n",
      "87190 frames over 272 games, mean reward 7.830, eps 0.13, speed 26.02 f/s\n",
      "87550 frames over 273 games, mean reward 7.850, eps 0.12, speed 28.56 f/s\n",
      "Best mean reward updated 7.830 -> 7.850, model saved\n",
      "87836 frames over 274 games, mean reward 7.870, eps 0.12, speed 29.55 f/s\n",
      "Best mean reward updated 7.850 -> 7.870, model saved\n",
      "88443 frames over 275 games, mean reward 8.070, eps 0.12, speed 26.12 f/s\n",
      "Best mean reward updated 7.870 -> 8.070, model saved\n",
      "88870 frames over 276 games, mean reward 8.100, eps 0.11, speed 25.33 f/s\n",
      "Best mean reward updated 8.070 -> 8.100, model saved\n",
      "89329 frames over 277 games, mean reward 8.110, eps 0.11, speed 26.70 f/s\n",
      "Best mean reward updated 8.100 -> 8.110, model saved\n",
      "89847 frames over 278 games, mean reward 8.070, eps 0.10, speed 26.87 f/s\n",
      "90249 frames over 279 games, mean reward 8.090, eps 0.10, speed 27.05 f/s\n",
      "90591 frames over 280 games, mean reward 8.090, eps 0.09, speed 28.38 f/s\n",
      "91146 frames over 281 games, mean reward 8.120, eps 0.09, speed 29.16 f/s\n",
      "Best mean reward updated 8.110 -> 8.120, model saved\n",
      "91680 frames over 282 games, mean reward 8.210, eps 0.08, speed 28.95 f/s\n",
      "Best mean reward updated 8.120 -> 8.210, model saved\n",
      "92093 frames over 283 games, mean reward 8.210, eps 0.08, speed 29.03 f/s\n",
      "92811 frames over 284 games, mean reward 8.220, eps 0.07, speed 28.90 f/s\n",
      "Best mean reward updated 8.210 -> 8.220, model saved\n",
      "93339 frames over 285 games, mean reward 8.310, eps 0.07, speed 28.82 f/s\n",
      "Best mean reward updated 8.220 -> 8.310, model saved\n",
      "93613 frames over 286 games, mean reward 8.280, eps 0.06, speed 28.73 f/s\n",
      "93917 frames over 287 games, mean reward 8.330, eps 0.06, speed 29.09 f/s\n",
      "Best mean reward updated 8.310 -> 8.330, model saved\n",
      "94388 frames over 288 games, mean reward 8.380, eps 0.06, speed 29.01 f/s\n",
      "Best mean reward updated 8.330 -> 8.380, model saved\n",
      "94796 frames over 289 games, mean reward 8.430, eps 0.05, speed 29.03 f/s\n",
      "Best mean reward updated 8.380 -> 8.430, model saved\n",
      "95271 frames over 290 games, mean reward 8.480, eps 0.05, speed 27.32 f/s\n",
      "Best mean reward updated 8.430 -> 8.480, model saved\n",
      "95840 frames over 291 games, mean reward 8.540, eps 0.04, speed 25.87 f/s\n",
      "Best mean reward updated 8.480 -> 8.540, model saved\n",
      "96261 frames over 292 games, mean reward 8.540, eps 0.04, speed 26.43 f/s\n",
      "97391 frames over 293 games, mean reward 8.680, eps 0.03, speed 27.13 f/s\n",
      "Best mean reward updated 8.540 -> 8.680, model saved\n",
      "97952 frames over 294 games, mean reward 8.820, eps 0.02, speed 29.22 f/s\n",
      "Best mean reward updated 8.680 -> 8.820, model saved\n",
      "98533 frames over 295 games, mean reward 8.870, eps 0.02, speed 29.18 f/s\n",
      "Best mean reward updated 8.820 -> 8.870, model saved\n",
      "98997 frames over 296 games, mean reward 8.960, eps 0.02, speed 28.92 f/s\n",
      "Best mean reward updated 8.870 -> 8.960, model saved\n",
      "99675 frames over 297 games, mean reward 8.950, eps 0.02, speed 28.32 f/s\n",
      "100538 frames over 298 games, mean reward 9.020, eps 0.02, speed 29.00 f/s\n",
      "Best mean reward updated 8.960 -> 9.020, model saved\n",
      "101031 frames over 299 games, mean reward 9.060, eps 0.02, speed 28.70 f/s\n",
      "Best mean reward updated 9.020 -> 9.060, model saved\n",
      "101290 frames over 300 games, mean reward 9.070, eps 0.02, speed 28.90 f/s\n",
      "Best mean reward updated 9.060 -> 9.070, model saved\n",
      "102378 frames over 301 games, mean reward 9.160, eps 0.02, speed 28.83 f/s\n",
      "Best mean reward updated 9.070 -> 9.160, model saved\n",
      "103306 frames over 302 games, mean reward 9.160, eps 0.02, speed 28.87 f/s\n",
      "103681 frames over 303 games, mean reward 9.210, eps 0.02, speed 28.73 f/s\n",
      "Best mean reward updated 9.160 -> 9.210, model saved\n",
      "104220 frames over 304 games, mean reward 9.400, eps 0.02, speed 28.81 f/s\n",
      "Best mean reward updated 9.210 -> 9.400, model saved\n",
      "104807 frames over 305 games, mean reward 9.570, eps 0.02, speed 28.86 f/s\n",
      "Best mean reward updated 9.400 -> 9.570, model saved\n",
      "105267 frames over 306 games, mean reward 9.620, eps 0.02, speed 26.37 f/s\n",
      "Best mean reward updated 9.570 -> 9.620, model saved\n",
      "105675 frames over 307 games, mean reward 9.620, eps 0.02, speed 28.96 f/s\n",
      "105914 frames over 308 games, mean reward 9.560, eps 0.02, speed 27.03 f/s\n",
      "106433 frames over 309 games, mean reward 9.590, eps 0.02, speed 24.92 f/s\n",
      "106918 frames over 310 games, mean reward 9.640, eps 0.02, speed 26.84 f/s\n",
      "Best mean reward updated 9.620 -> 9.640, model saved\n",
      "107477 frames over 311 games, mean reward 9.720, eps 0.02, speed 28.90 f/s\n",
      "Best mean reward updated 9.640 -> 9.720, model saved\n",
      "108137 frames over 312 games, mean reward 9.780, eps 0.02, speed 28.89 f/s\n",
      "Best mean reward updated 9.720 -> 9.780, model saved\n",
      "108647 frames over 313 games, mean reward 9.850, eps 0.02, speed 28.88 f/s\n",
      "Best mean reward updated 9.780 -> 9.850, model saved\n",
      "109077 frames over 314 games, mean reward 9.950, eps 0.02, speed 28.97 f/s\n",
      "Best mean reward updated 9.850 -> 9.950, model saved\n",
      "109789 frames over 315 games, mean reward 10.110, eps 0.02, speed 29.09 f/s\n",
      "Best mean reward updated 9.950 -> 10.110, model saved\n",
      "110546 frames over 316 games, mean reward 10.270, eps 0.02, speed 28.92 f/s\n",
      "Best mean reward updated 10.110 -> 10.270, model saved\n",
      "111060 frames over 317 games, mean reward 10.160, eps 0.02, speed 29.13 f/s\n",
      "111874 frames over 318 games, mean reward 10.270, eps 0.02, speed 25.26 f/s\n",
      "112358 frames over 319 games, mean reward 10.340, eps 0.02, speed 23.51 f/s\n",
      "Best mean reward updated 10.270 -> 10.340, model saved\n",
      "112856 frames over 320 games, mean reward 10.350, eps 0.02, speed 23.34 f/s\n",
      "Best mean reward updated 10.340 -> 10.350, model saved\n",
      "113368 frames over 321 games, mean reward 10.410, eps 0.02, speed 27.74 f/s\n",
      "Best mean reward updated 10.350 -> 10.410, model saved\n",
      "113867 frames over 322 games, mean reward 10.420, eps 0.02, speed 26.84 f/s\n",
      "Best mean reward updated 10.410 -> 10.420, model saved\n",
      "114556 frames over 323 games, mean reward 10.550, eps 0.02, speed 24.67 f/s\n",
      "Best mean reward updated 10.420 -> 10.550, model saved\n",
      "115078 frames over 324 games, mean reward 10.610, eps 0.02, speed 27.90 f/s\n",
      "Best mean reward updated 10.550 -> 10.610, model saved\n",
      "115515 frames over 325 games, mean reward 10.660, eps 0.02, speed 28.00 f/s\n",
      "Best mean reward updated 10.610 -> 10.660, model saved\n",
      "116289 frames over 326 games, mean reward 10.810, eps 0.02, speed 25.99 f/s\n",
      "Best mean reward updated 10.660 -> 10.810, model saved\n",
      "116807 frames over 327 games, mean reward 10.920, eps 0.02, speed 26.47 f/s\n",
      "Best mean reward updated 10.810 -> 10.920, model saved\n",
      "117357 frames over 328 games, mean reward 10.960, eps 0.02, speed 26.61 f/s\n",
      "Best mean reward updated 10.920 -> 10.960, model saved\n",
      "118496 frames over 329 games, mean reward 11.070, eps 0.02, speed 26.67 f/s\n",
      "Best mean reward updated 10.960 -> 11.070, model saved\n",
      "119256 frames over 330 games, mean reward 11.160, eps 0.02, speed 26.88 f/s\n",
      "Best mean reward updated 11.070 -> 11.160, model saved\n",
      "120036 frames over 331 games, mean reward 11.320, eps 0.02, speed 27.01 f/s\n",
      "Best mean reward updated 11.160 -> 11.320, model saved\n",
      "120772 frames over 332 games, mean reward 11.350, eps 0.02, speed 26.63 f/s\n",
      "Best mean reward updated 11.320 -> 11.350, model saved\n",
      "121349 frames over 333 games, mean reward 11.330, eps 0.02, speed 26.73 f/s\n",
      "121780 frames over 334 games, mean reward 11.380, eps 0.02, speed 27.02 f/s\n",
      "Best mean reward updated 11.350 -> 11.380, model saved\n",
      "122425 frames over 335 games, mean reward 11.510, eps 0.02, speed 26.64 f/s\n",
      "Best mean reward updated 11.380 -> 11.510, model saved\n",
      "122927 frames over 336 games, mean reward 11.560, eps 0.02, speed 26.56 f/s\n",
      "Best mean reward updated 11.510 -> 11.560, model saved\n",
      "123310 frames over 337 games, mean reward 11.560, eps 0.02, speed 26.71 f/s\n",
      "123840 frames over 338 games, mean reward 11.600, eps 0.02, speed 26.71 f/s\n",
      "Best mean reward updated 11.560 -> 11.600, model saved\n",
      "124736 frames over 339 games, mean reward 11.620, eps 0.02, speed 26.57 f/s\n",
      "Best mean reward updated 11.600 -> 11.620, model saved\n",
      "125140 frames over 340 games, mean reward 11.700, eps 0.02, speed 27.07 f/s\n",
      "Best mean reward updated 11.620 -> 11.700, model saved\n",
      "125429 frames over 341 games, mean reward 11.640, eps 0.02, speed 26.97 f/s\n",
      "125846 frames over 342 games, mean reward 11.740, eps 0.02, speed 26.70 f/s\n",
      "Best mean reward updated 11.700 -> 11.740, model saved\n",
      "126330 frames over 343 games, mean reward 11.770, eps 0.02, speed 26.61 f/s\n",
      "Best mean reward updated 11.740 -> 11.770, model saved\n",
      "127021 frames over 344 games, mean reward 11.870, eps 0.02, speed 26.96 f/s\n",
      "Best mean reward updated 11.770 -> 11.870, model saved\n",
      "127428 frames over 345 games, mean reward 11.870, eps 0.02, speed 26.40 f/s\n",
      "127927 frames over 346 games, mean reward 11.820, eps 0.02, speed 26.62 f/s\n",
      "128563 frames over 347 games, mean reward 11.890, eps 0.02, speed 27.00 f/s\n",
      "Best mean reward updated 11.870 -> 11.890, model saved\n",
      "128934 frames over 348 games, mean reward 11.910, eps 0.02, speed 26.97 f/s\n",
      "Best mean reward updated 11.890 -> 11.910, model saved\n",
      "129396 frames over 349 games, mean reward 11.940, eps 0.02, speed 27.03 f/s\n",
      "Best mean reward updated 11.910 -> 11.940, model saved\n",
      "129644 frames over 350 games, mean reward 11.850, eps 0.02, speed 26.88 f/s\n",
      "130087 frames over 351 games, mean reward 11.840, eps 0.02, speed 27.07 f/s\n",
      "130635 frames over 352 games, mean reward 11.800, eps 0.02, speed 26.88 f/s\n",
      "131153 frames over 353 games, mean reward 11.820, eps 0.02, speed 26.92 f/s\n",
      "131579 frames over 354 games, mean reward 11.930, eps 0.02, speed 26.98 f/s\n",
      "132277 frames over 355 games, mean reward 12.000, eps 0.02, speed 26.96 f/s\n",
      "Best mean reward updated 11.940 -> 12.000, model saved\n",
      "132656 frames over 356 games, mean reward 11.980, eps 0.02, speed 27.14 f/s\n",
      "133671 frames over 357 games, mean reward 12.090, eps 0.02, speed 26.93 f/s\n",
      "Best mean reward updated 12.000 -> 12.090, model saved\n",
      "134159 frames over 358 games, mean reward 12.140, eps 0.02, speed 26.87 f/s\n",
      "Best mean reward updated 12.090 -> 12.140, model saved\n",
      "134663 frames over 359 games, mean reward 12.220, eps 0.02, speed 27.03 f/s\n",
      "Best mean reward updated 12.140 -> 12.220, model saved\n",
      "135172 frames over 360 games, mean reward 12.280, eps 0.02, speed 26.82 f/s\n",
      "Best mean reward updated 12.220 -> 12.280, model saved\n",
      "136000 frames over 361 games, mean reward 12.430, eps 0.02, speed 27.03 f/s\n",
      "Best mean reward updated 12.280 -> 12.430, model saved\n",
      "136421 frames over 362 games, mean reward 12.400, eps 0.02, speed 26.96 f/s\n",
      "136851 frames over 363 games, mean reward 12.410, eps 0.02, speed 26.92 f/s\n",
      "137171 frames over 364 games, mean reward 12.340, eps 0.02, speed 26.97 f/s\n",
      "137918 frames over 365 games, mean reward 12.390, eps 0.02, speed 26.84 f/s\n",
      "138907 frames over 366 games, mean reward 12.410, eps 0.02, speed 26.88 f/s\n",
      "139436 frames over 367 games, mean reward 12.410, eps 0.02, speed 26.94 f/s\n",
      "139821 frames over 368 games, mean reward 12.400, eps 0.02, speed 26.80 f/s\n",
      "140279 frames over 369 games, mean reward 12.430, eps 0.02, speed 26.98 f/s\n",
      "140761 frames over 370 games, mean reward 12.440, eps 0.02, speed 26.97 f/s\n",
      "Best mean reward updated 12.430 -> 12.440, model saved\n",
      "141235 frames over 371 games, mean reward 12.550, eps 0.02, speed 26.97 f/s\n",
      "Best mean reward updated 12.440 -> 12.550, model saved\n",
      "141609 frames over 372 games, mean reward 12.590, eps 0.02, speed 26.93 f/s\n",
      "Best mean reward updated 12.550 -> 12.590, model saved\n",
      "142127 frames over 373 games, mean reward 12.630, eps 0.02, speed 27.03 f/s\n",
      "Best mean reward updated 12.590 -> 12.630, model saved\n",
      "142613 frames over 374 games, mean reward 12.720, eps 0.02, speed 27.01 f/s\n",
      "Best mean reward updated 12.630 -> 12.720, model saved\n",
      "143199 frames over 375 games, mean reward 12.640, eps 0.02, speed 27.00 f/s\n",
      "143901 frames over 376 games, mean reward 12.690, eps 0.02, speed 27.04 f/s\n",
      "144317 frames over 377 games, mean reward 12.690, eps 0.02, speed 27.12 f/s\n",
      "144976 frames over 378 games, mean reward 12.770, eps 0.02, speed 27.10 f/s\n",
      "Best mean reward updated 12.720 -> 12.770, model saved\n",
      "145685 frames over 379 games, mean reward 12.910, eps 0.02, speed 27.08 f/s\n",
      "Best mean reward updated 12.770 -> 12.910, model saved\n",
      "146198 frames over 380 games, mean reward 12.970, eps 0.02, speed 27.06 f/s\n",
      "Best mean reward updated 12.910 -> 12.970, model saved\n",
      "146703 frames over 381 games, mean reward 13.020, eps 0.02, speed 26.91 f/s\n",
      "Best mean reward updated 12.970 -> 13.020, model saved\n",
      "147345 frames over 382 games, mean reward 12.990, eps 0.02, speed 27.21 f/s\n",
      "148113 frames over 383 games, mean reward 13.140, eps 0.02, speed 27.16 f/s\n",
      "Best mean reward updated 13.020 -> 13.140, model saved\n",
      "148478 frames over 384 games, mean reward 13.140, eps 0.02, speed 26.76 f/s\n",
      "148913 frames over 385 games, mean reward 13.110, eps 0.02, speed 26.98 f/s\n",
      "149306 frames over 386 games, mean reward 13.180, eps 0.02, speed 26.97 f/s\n",
      "Best mean reward updated 13.140 -> 13.180, model saved\n",
      "149708 frames over 387 games, mean reward 13.160, eps 0.02, speed 27.19 f/s\n",
      "150235 frames over 388 games, mean reward 13.200, eps 0.02, speed 27.12 f/s\n",
      "Best mean reward updated 13.180 -> 13.200, model saved\n",
      "150778 frames over 389 games, mean reward 13.250, eps 0.02, speed 27.15 f/s\n",
      "Best mean reward updated 13.200 -> 13.250, model saved\n",
      "151263 frames over 390 games, mean reward 13.250, eps 0.02, speed 27.07 f/s\n",
      "151806 frames over 391 games, mean reward 13.260, eps 0.02, speed 27.00 f/s\n",
      "Best mean reward updated 13.250 -> 13.260, model saved\n",
      "152304 frames over 392 games, mean reward 13.290, eps 0.02, speed 27.06 f/s\n",
      "Best mean reward updated 13.260 -> 13.290, model saved\n",
      "152655 frames over 393 games, mean reward 13.200, eps 0.02, speed 27.02 f/s\n",
      "152996 frames over 394 games, mean reward 13.080, eps 0.02, speed 27.14 f/s\n",
      "153523 frames over 395 games, mean reward 13.090, eps 0.02, speed 27.08 f/s\n",
      "154311 frames over 396 games, mean reward 13.150, eps 0.02, speed 27.10 f/s\n",
      "154798 frames over 397 games, mean reward 13.270, eps 0.02, speed 27.12 f/s\n",
      "155325 frames over 398 games, mean reward 13.300, eps 0.02, speed 27.28 f/s\n",
      "Best mean reward updated 13.290 -> 13.300, model saved\n",
      "155759 frames over 399 games, mean reward 13.310, eps 0.02, speed 27.02 f/s\n",
      "Best mean reward updated 13.300 -> 13.310, model saved\n",
      "156208 frames over 400 games, mean reward 13.360, eps 0.02, speed 27.14 f/s\n",
      "Best mean reward updated 13.310 -> 13.360, model saved\n",
      "156760 frames over 401 games, mean reward 13.440, eps 0.02, speed 27.15 f/s\n",
      "Best mean reward updated 13.360 -> 13.440, model saved\n",
      "157198 frames over 402 games, mean reward 13.420, eps 0.02, speed 27.29 f/s\n",
      "157791 frames over 403 games, mean reward 13.580, eps 0.02, speed 27.22 f/s\n",
      "Best mean reward updated 13.440 -> 13.580, model saved\n",
      "158351 frames over 404 games, mean reward 13.560, eps 0.02, speed 27.24 f/s\n",
      "159005 frames over 405 games, mean reward 13.490, eps 0.02, speed 27.30 f/s\n",
      "159596 frames over 406 games, mean reward 13.540, eps 0.02, speed 27.30 f/s\n",
      "160118 frames over 407 games, mean reward 13.580, eps 0.02, speed 27.18 f/s\n",
      "160528 frames over 408 games, mean reward 13.760, eps 0.02, speed 27.32 f/s\n",
      "Best mean reward updated 13.580 -> 13.760, model saved\n",
      "161198 frames over 409 games, mean reward 13.780, eps 0.02, speed 27.36 f/s\n",
      "Best mean reward updated 13.760 -> 13.780, model saved\n",
      "161952 frames over 410 games, mean reward 13.850, eps 0.02, speed 27.35 f/s\n",
      "Best mean reward updated 13.780 -> 13.850, model saved\n",
      "162442 frames over 411 games, mean reward 13.870, eps 0.02, speed 27.36 f/s\n",
      "Best mean reward updated 13.850 -> 13.870, model saved\n",
      "162866 frames over 412 games, mean reward 13.830, eps 0.02, speed 27.36 f/s\n",
      "163296 frames over 413 games, mean reward 13.810, eps 0.02, speed 27.28 f/s\n",
      "163711 frames over 414 games, mean reward 13.810, eps 0.02, speed 27.25 f/s\n",
      "164095 frames over 415 games, mean reward 13.770, eps 0.02, speed 27.18 f/s\n",
      "164745 frames over 416 games, mean reward 13.790, eps 0.02, speed 27.34 f/s\n",
      "165359 frames over 417 games, mean reward 13.880, eps 0.02, speed 27.33 f/s\n",
      "Best mean reward updated 13.870 -> 13.880, model saved\n",
      "165815 frames over 418 games, mean reward 13.820, eps 0.02, speed 27.35 f/s\n",
      "166326 frames over 419 games, mean reward 13.830, eps 0.02, speed 27.40 f/s\n",
      "166765 frames over 420 games, mean reward 13.870, eps 0.02, speed 27.33 f/s\n",
      "167313 frames over 421 games, mean reward 13.900, eps 0.02, speed 27.36 f/s\n",
      "Best mean reward updated 13.880 -> 13.900, model saved\n",
      "167833 frames over 422 games, mean reward 13.940, eps 0.02, speed 27.19 f/s\n",
      "Best mean reward updated 13.900 -> 13.940, model saved\n",
      "168250 frames over 423 games, mean reward 13.890, eps 0.02, speed 23.18 f/s\n",
      "168697 frames over 424 games, mean reward 13.880, eps 0.02, speed 27.09 f/s\n",
      "169011 frames over 425 games, mean reward 13.870, eps 0.02, speed 27.14 f/s\n",
      "169725 frames over 426 games, mean reward 13.780, eps 0.02, speed 27.44 f/s\n",
      "170258 frames over 427 games, mean reward 13.750, eps 0.02, speed 27.86 f/s\n",
      "170611 frames over 428 games, mean reward 13.710, eps 0.02, speed 28.25 f/s\n",
      "171143 frames over 429 games, mean reward 13.650, eps 0.02, speed 27.60 f/s\n",
      "171632 frames over 430 games, mean reward 13.540, eps 0.02, speed 28.46 f/s\n",
      "172065 frames over 431 games, mean reward 13.420, eps 0.02, speed 27.11 f/s\n",
      "172542 frames over 432 games, mean reward 13.390, eps 0.02, speed 29.50 f/s\n",
      "172939 frames over 433 games, mean reward 13.320, eps 0.02, speed 29.73 f/s\n",
      "173882 frames over 434 games, mean reward 13.390, eps 0.02, speed 29.30 f/s\n",
      "174448 frames over 435 games, mean reward 13.250, eps 0.02, speed 29.35 f/s\n",
      "175109 frames over 436 games, mean reward 13.260, eps 0.02, speed 29.55 f/s\n",
      "175396 frames over 437 games, mean reward 13.240, eps 0.02, speed 29.39 f/s\n",
      "175794 frames over 438 games, mean reward 13.290, eps 0.02, speed 29.17 f/s\n",
      "176176 frames over 439 games, mean reward 13.240, eps 0.02, speed 28.39 f/s\n",
      "176645 frames over 440 games, mean reward 13.210, eps 0.02, speed 24.87 f/s\n",
      "177085 frames over 441 games, mean reward 13.320, eps 0.02, speed 24.89 f/s\n",
      "177838 frames over 442 games, mean reward 13.320, eps 0.02, speed 26.20 f/s\n",
      "178393 frames over 443 games, mean reward 13.340, eps 0.02, speed 28.64 f/s\n",
      "178912 frames over 444 games, mean reward 13.250, eps 0.02, speed 28.48 f/s\n",
      "179320 frames over 445 games, mean reward 13.300, eps 0.02, speed 28.90 f/s\n",
      "179904 frames over 446 games, mean reward 13.340, eps 0.02, speed 28.75 f/s\n",
      "180240 frames over 447 games, mean reward 13.270, eps 0.02, speed 28.83 f/s\n",
      "180811 frames over 448 games, mean reward 13.350, eps 0.02, speed 28.55 f/s\n",
      "181276 frames over 449 games, mean reward 13.390, eps 0.02, speed 29.30 f/s\n",
      "181561 frames over 450 games, mean reward 13.430, eps 0.02, speed 29.32 f/s\n",
      "182152 frames over 451 games, mean reward 13.490, eps 0.02, speed 29.27 f/s\n",
      "182499 frames over 452 games, mean reward 13.440, eps 0.02, speed 29.33 f/s\n",
      "183122 frames over 453 games, mean reward 13.400, eps 0.02, speed 29.35 f/s\n",
      "183722 frames over 454 games, mean reward 13.280, eps 0.02, speed 29.09 f/s\n",
      "184375 frames over 455 games, mean reward 13.310, eps 0.02, speed 29.18 f/s\n",
      "184952 frames over 456 games, mean reward 13.340, eps 0.02, speed 29.15 f/s\n",
      "185581 frames over 457 games, mean reward 13.250, eps 0.02, speed 29.14 f/s\n",
      "186083 frames over 458 games, mean reward 13.300, eps 0.02, speed 29.24 f/s\n",
      "186657 frames over 459 games, mean reward 13.330, eps 0.02, speed 29.09 f/s\n",
      "187055 frames over 460 games, mean reward 13.330, eps 0.02, speed 29.14 f/s\n",
      "187461 frames over 461 games, mean reward 13.240, eps 0.02, speed 29.27 f/s\n",
      "188168 frames over 462 games, mean reward 13.300, eps 0.02, speed 29.05 f/s\n",
      "188634 frames over 463 games, mean reward 13.310, eps 0.02, speed 29.19 f/s\n",
      "189080 frames over 464 games, mean reward 13.340, eps 0.02, speed 29.21 f/s\n",
      "189457 frames over 465 games, mean reward 13.370, eps 0.02, speed 29.23 f/s\n",
      "189834 frames over 466 games, mean reward 13.240, eps 0.02, speed 29.16 f/s\n",
      "190105 frames over 467 games, mean reward 13.180, eps 0.02, speed 29.16 f/s\n",
      "190799 frames over 468 games, mean reward 13.330, eps 0.02, speed 29.11 f/s\n",
      "191329 frames over 469 games, mean reward 13.290, eps 0.02, speed 29.30 f/s\n",
      "192325 frames over 470 games, mean reward 13.280, eps 0.02, speed 29.17 f/s\n",
      "192833 frames over 471 games, mean reward 13.180, eps 0.02, speed 29.15 f/s\n",
      "193445 frames over 472 games, mean reward 13.220, eps 0.02, speed 29.17 f/s\n",
      "193782 frames over 473 games, mean reward 13.220, eps 0.02, speed 28.94 f/s\n",
      "194260 frames over 474 games, mean reward 13.170, eps 0.02, speed 28.32 f/s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 72\u001b[0m\n\u001b[0;32m     70\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     71\u001b[0m batch \u001b[39m=\u001b[39m buffer\u001b[39m.\u001b[39msample(BATCH_SIZE)\n\u001b[1;32m---> 72\u001b[0m loss_t \u001b[39m=\u001b[39m calc_loss(batch, net, tgt_net, device\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     73\u001b[0m loss_t\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     74\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[20], line 12\u001b[0m, in \u001b[0;36mcalc_loss\u001b[1;34m(batch, net, tgt_net, device)\u001b[0m\n\u001b[0;32m      8\u001b[0m done_mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mByteTensor(dones)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     10\u001b[0m actions_v2 \u001b[39m=\u001b[39m actions_v\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mlong()\n\u001b[1;32m---> 12\u001b[0m state_action_values \u001b[39m=\u001b[39m net(states_v)\u001b[39m.\u001b[39mgather(\u001b[39m1\u001b[39m, actions_v2)\u001b[39m.\u001b[39msqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     14\u001b[0m next_state_values \u001b[39m=\u001b[39m tgt_net(next_states_v)\u001b[39m.\u001b[39mmax(\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     15\u001b[0m next_state_values[done_mask] \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\NEURO140\\Final\\lib\\dqn_model.py:32\u001b[0m, in \u001b[0;36mDQN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 32\u001b[0m     conv_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv(x)\u001b[39m.\u001b[39mview(x\u001b[39m.\u001b[39msize()[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     33\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(conv_out)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# device = torch.device(\"gpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "env = wrappers.make_env(DEFAULT_ENV_NAME)\n",
    "\n",
    "net = dqn_model.DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
    "tgt_net = dqn_model.DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
    "writer = SummaryWriter(comment=\"-\" + DEFAULT_ENV_NAME)\n",
    "print(net)\n",
    "\n",
    "buffer = ExperienceBuffer(REPLAY_SIZE)\n",
    "agent = Agent(env, buffer)\n",
    "epsilon = EPSILON_START\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "total_rewards = []\n",
    "frame_idx = 0\n",
    "ts_frame = 0\n",
    "ts = time.time()\n",
    "best_mean_reward = None\n",
    "\n",
    "NUM_GAMES = 4000\n",
    "\n",
    "# for plots\n",
    "mean_rewards = []\n",
    "num_games = []\n",
    "epsilons = []\n",
    "frames = []\n",
    "\n",
    "\n",
    "while len(total_rewards) < NUM_GAMES:\n",
    "    frame_idx += 1\n",
    "    epsilon = max(EPSILON_FINAL, EPSILON_START - frame_idx / EPSILON_DECAY_LAST_FRAME)\n",
    "    if frame_idx % 100 == 0:\n",
    "        epsilons.append(epsilon)\n",
    "        frames.append(frame_idx)\n",
    "\n",
    "    reward = agent.play_step(net, epsilon, device=device)\n",
    "    if reward is not None and reward > 0:\n",
    "        total_rewards.append(reward)\n",
    "        speed = (frame_idx - ts_frame) / (time.time() - ts)\n",
    "        ts_frame = frame_idx\n",
    "        ts = time.time()\n",
    "        mean_reward = np.mean(total_rewards[-100:])\n",
    "        mean_rewards.append(mean_reward)\n",
    "        num_games.append(len(total_rewards))\n",
    "        print(\"%d frames over %d games, mean reward %.3f, eps %.2f, speed %.2f f/s\" % (\n",
    "            frame_idx, len(total_rewards), mean_reward, epsilon,\n",
    "            speed\n",
    "        ))\n",
    "        writer.add_scalar(\"epsilon\", epsilon, frame_idx)\n",
    "        writer.add_scalar(\"speed\", speed, frame_idx)\n",
    "        writer.add_scalar(\"reward_100\", mean_reward, frame_idx)\n",
    "        writer.add_scalar(\"reward\", reward, frame_idx)\n",
    "        if best_mean_reward is None or best_mean_reward < mean_reward:\n",
    "            torch.save(net.state_dict(), DEFAULT_ENV_NAME + \"-best.dat\")\n",
    "            if best_mean_reward is not None:\n",
    "                print(\"Best mean reward updated %.3f -> %.3f, model saved\" % (best_mean_reward, mean_reward))\n",
    "            best_mean_reward = mean_reward\n",
    "        if mean_reward > MEAN_REWARD_BOUND:\n",
    "            print(\"Solved in %d frames!\" % frame_idx)\n",
    "            break\n",
    "\n",
    "    if len(buffer) < REPLAY_START_SIZE:\n",
    "        continue\n",
    "\n",
    "    if frame_idx % SYNC_TARGET_FRAMES == 0:\n",
    "        tgt_net.load_state_dict(net.state_dict())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    batch = buffer.sample(BATCH_SIZE)\n",
    "    loss_t = calc_loss(batch, net, tgt_net, device='cpu')\n",
    "    loss_t.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "writer.close()\n",
    "\n",
    "plt.plot(num_games, mean_rewards)\n",
    "plt.xlabel('Number of games played')\n",
    "plt.ylabel('Mean reward')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, len(total_rewards)+1), total_rewards)\n",
    "plt.xlabel('Number of games played')\n",
    "plt.ylabel('Total reward')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(total_rewards, bins=30)\n",
    "plt.xlabel('Reward')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(frames, epsilons)\n",
    "plt.xlabel('Number of frames played')\n",
    "plt.ylabel('Epsilon')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "EasyProcessError",
     "evalue": "start error <EasyProcess cmd_param=['Xvfb', '-help'] cmd=['Xvfb', '-help'] oserror=[WinError 2] The system cannot find the file specified return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\easyprocess\\__init__.py:176\u001b[0m, in \u001b[0;36mEasyProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpopen \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mPopen(\n\u001b[0;32m    177\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcmd,\n\u001b[0;32m    178\u001b[0m         stdout\u001b[39m=\u001b[39;49mstdout,\n\u001b[0;32m    179\u001b[0m         stderr\u001b[39m=\u001b[39;49mstderr,\n\u001b[0;32m    180\u001b[0m         cwd\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcwd,\n\u001b[0;32m    181\u001b[0m         env\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv,\n\u001b[0;32m    182\u001b[0m     )\n\u001b[0;32m    183\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m oserror:\n",
      "File \u001b[1;32mc:\\Python39\\lib\\subprocess.py:947\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[0;32m    945\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m--> 947\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m    948\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m    949\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m    950\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m    951\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m    952\u001b[0m                         errread, errwrite,\n\u001b[0;32m    953\u001b[0m                         restore_signals,\n\u001b[0;32m    954\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m    955\u001b[0m                         start_new_session)\n\u001b[0;32m    956\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m    957\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python39\\lib\\subprocess.py:1416\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1416\u001b[0m     hp, ht, pid, tid \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39;49mCreateProcess(executable, args,\n\u001b[0;32m   1417\u001b[0m                              \u001b[39m# no special security\u001b[39;49;00m\n\u001b[0;32m   1418\u001b[0m                              \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1419\u001b[0m                              \u001b[39mint\u001b[39;49m(\u001b[39mnot\u001b[39;49;00m close_fds),\n\u001b[0;32m   1420\u001b[0m                              creationflags,\n\u001b[0;32m   1421\u001b[0m                              env,\n\u001b[0;32m   1422\u001b[0m                              cwd,\n\u001b[0;32m   1423\u001b[0m                              startupinfo)\n\u001b[0;32m   1424\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1425\u001b[0m     \u001b[39m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1426\u001b[0m     \u001b[39m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1429\u001b[0m     \u001b[39m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1430\u001b[0m     \u001b[39m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mEasyProcessError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpyvirtualdisplay\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m _display \u001b[39m=\u001b[39m pyvirtualdisplay\u001b[39m.\u001b[39;49mDisplay(visible\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, size\u001b[39m=\u001b[39;49m(\u001b[39m1400\u001b[39;49m, \u001b[39m900\u001b[39;49m))\n\u001b[0;32m      3\u001b[0m _ \u001b[39m=\u001b[39m _display\u001b[39m.\u001b[39mstart()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pyvirtualdisplay\\display.py:34\u001b[0m, in \u001b[0;36mDisplay.__init__\u001b[1;34m(self, backend, visible, size, color_depth, bgcolor, use_xauth, check_startup, randomizer, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackend \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mxvfb\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 34\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdisplay_class(\n\u001b[0;32m     35\u001b[0m     size\u001b[39m=\u001b[39msize,\n\u001b[0;32m     36\u001b[0m     color_depth\u001b[39m=\u001b[39mcolor_depth,\n\u001b[0;32m     37\u001b[0m     bgcolor\u001b[39m=\u001b[39mbgcolor,\n\u001b[0;32m     38\u001b[0m     randomizer\u001b[39m=\u001b[39mrandomizer,\n\u001b[0;32m     39\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     40\u001b[0m AbstractDisplay\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, use_xauth\u001b[39m=\u001b[39muse_xauth, check_startup\u001b[39m=\u001b[39mcheck_startup, randomizer\u001b[39m=\u001b[39mrandomizer)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pyvirtualdisplay\\display.py:53\u001b[0m, in \u001b[0;36mDisplay.display_class\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m XephyrDisplay\n\u001b[0;32m     52\u001b[0m \u001b[39m# TODO: check only once\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_installed()\n\u001b[0;32m     55\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pyvirtualdisplay\\xvfb.py:40\u001b[0m, in \u001b[0;36mXvfbDisplay.check_installed\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m     38\u001b[0m p\u001b[39m.\u001b[39menable_stdout_log \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m     39\u001b[0m p\u001b[39m.\u001b[39menable_stderr_log \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m p\u001b[39m.\u001b[39;49mcall()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\easyprocess\\__init__.py:147\u001b[0m, in \u001b[0;36mEasyProcess.call\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Run command with arguments. Wait for command to complete.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \n\u001b[0;32m    138\u001b[0m \u001b[39msame as:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    144\u001b[0m \n\u001b[0;32m    145\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstart()\u001b[39m.\u001b[39mwait(timeout\u001b[39m=\u001b[39mtimeout)\n\u001b[0;32m    148\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_alive():\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\easyprocess\\__init__.py:186\u001b[0m, in \u001b[0;36mEasyProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    184\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mOSError exception: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, oserror)\n\u001b[0;32m    185\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moserror \u001b[39m=\u001b[39m oserror\n\u001b[1;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m EasyProcessError(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstart error\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    187\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_started \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    188\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mprocess was started (pid=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpid)\n",
      "\u001b[1;31mEasyProcessError\u001b[0m: start error <EasyProcess cmd_param=['Xvfb', '-help'] cmd=['Xvfb', '-help'] oserror=[WinError 2] The system cannot find the file specified return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
